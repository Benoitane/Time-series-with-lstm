{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_for_TS_using_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab9UAfQY-DxH",
        "outputId": "ed1d9c2a-0d71-4955-80ea-200206048789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnTV5Y9T-3Jj",
        "outputId": "4d83fa8d-662e-42fd-e95e-c8669ec86084"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from datetime import datetime, date\n",
        "import holidays\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "import plotly.offline as pyo"
      ],
      "metadata": {
        "id": "GyHTFnJN-LUh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"{device}\" \" is available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAq2qvs4-LXJ",
        "outputId": "f6f61b25-6874-4d2c-d4c6-fb50a0327819"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B-dDBRgbQrvY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('PJME_hourly.csv')\n",
        "df = df.set_index(['Datetime'])\n",
        "df = df.rename(columns={'PJME_MW': 'value'})\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()"
      ],
      "metadata": {
        "id": "25R5TdSa-LZ2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dataset(df, title):\n",
        "    data = []\n",
        "    \n",
        "    value = go.Scatter(\n",
        "        x=df.index,\n",
        "        y=df.value,\n",
        "        mode=\"lines\",\n",
        "        name=\"values\",\n",
        "        marker=dict(),\n",
        "        text=df.index,\n",
        "        line=dict(color=\"rgba(0,0,0, 0.3)\"),\n",
        "    )\n",
        "    data.append(value)\n",
        "\n",
        "    layout = dict(\n",
        "        title=title,\n",
        "        xaxis=dict(title=\"Date\", ticklen=5, zeroline=False),\n",
        "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
        "    )\n",
        "\n",
        "    fig = dict(data=data, layout=layout)\n",
        "    iplot(fig)"
      ],
      "metadata": {
        "id": "1XNGA6oN-LcP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dataset(df, title='Représentation de la série temporelle')"
      ],
      "metadata": {
        "id": "PMC8yjjQ_iHP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_time_lags(df, n_lags):\n",
        "    df_n = df.copy()\n",
        "    for n in range(1, n_lags + 1):\n",
        "        df_n[f\"lag{n}\"] = df_n[\"value\"].shift(n)\n",
        "    df_n = df_n.iloc[n_lags:]\n",
        "    return df_n"
      ],
      "metadata": {
        "id": "Fs58flqZ_iKS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 100\n",
        "df_timelags = generate_time_lags(df, input_dim)"
      ],
      "metadata": {
        "id": "MFscTHAq_iM6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mriXuIsD-Le5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_encode_pd(df, cols):\n",
        "    for col in cols:\n",
        "        dummies = pd.get_dummies(df[col], prefix=col)\n",
        "    \n",
        "    return pd.concat([df, dummies], axis=1).drop(columns=cols)\n",
        "\n",
        "def generate_cyclical_features(df, col_name, period, start_num=0):\n",
        "    kwargs = {\n",
        "        f'sin_{col_name}' : lambda x: np.sin(2*np.pi*(df[col_name]-start_num)/period),\n",
        "        f'cos_{col_name}' : lambda x: np.cos(2*np.pi*(df[col_name]-start_num)/period)    \n",
        "             }\n",
        "    return df.assign(**kwargs).drop(columns=[col_name])\n",
        "\n",
        "def is_holiday(date):\n",
        "    date = date.replace(hour = 0)\n",
        "    return 1 if (date in us_holidays) else 0\n",
        "\n",
        "def add_holiday_col(df, holidays):\n",
        "    return df.assign(is_holiday = df.index.to_series().apply(is_holiday))"
      ],
      "metadata": {
        "id": "DP6NWVs9-Lhs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = (df.assign(hour = df.index.hour)\n",
        "                 .assign(day = df.index.day)\n",
        "                 .assign(month = df.index.month)\n",
        "                 .assign(day_of_week = df.index.dayofweek)\n",
        "                 .assign(week_of_year = df.index.week))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14JVyhx5G0Qr",
        "outputId": "7b7c5fb7-5b62-4bc6-9594-682bcd1f711c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning:\n",
            "\n",
            "weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = onehot_encode_pd(df_features, ['month','day','day_of_week','week_of_year'])"
      ],
      "metadata": {
        "id": "mquER-5p-Lks"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = generate_cyclical_features(df_features, 'hour', 24, 0)"
      ],
      "metadata": {
        "id": "Z8zygkulBhCf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_holidays = holidays.US()\n",
        "df_features = add_holiday_col(df_features, us_holidays)"
      ],
      "metadata": {
        "id": "4Yx-YbToBhFI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rCfZ0yFvBhHl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_label_split(df, target_col):\n",
        "    y = df[[target_col]]\n",
        "    X = df.drop(columns=[target_col])\n",
        "    return X, y\n",
        "\n",
        "def train_val_test_split(df, target_col, test_ratio):\n",
        "    val_ratio = test_ratio / (1 - test_ratio)\n",
        "    X, y = feature_label_split(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "def get_scaler(scaler):\n",
        "    scalers = {\n",
        "        \"minmax\": MinMaxScaler,\n",
        "        \"standard\": StandardScaler,\n",
        "        \"maxabs\": MaxAbsScaler,\n",
        "        \"robust\": RobustScaler,\n",
        "    }\n",
        "    return scalers.get(scaler.lower())()"
      ],
      "metadata": {
        "id": "K1TKVDBMBhKN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df_features, 'value', 0.2)"
      ],
      "metadata": {
        "id": "myLOUKOYFTC5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = get_scaler('minmax')\n",
        "X_train_arr = scaler.fit_transform(X_train)\n",
        "X_val_arr = scaler.transform(X_val)\n",
        "X_test_arr = scaler.transform(X_test)\n",
        "\n",
        "y_train_arr = scaler.fit_transform(y_train)\n",
        "y_val_arr = scaler.transform(y_val)\n",
        "y_test_arr = scaler.transform(y_test)"
      ],
      "metadata": {
        "id": "dbW8EjG3FTFX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_features = torch.Tensor(X_train_arr)\n",
        "train_targets = torch.Tensor(y_train_arr)\n",
        "val_features = torch.Tensor(X_val_arr)\n",
        "val_targets = torch.Tensor(y_val_arr)\n",
        "test_features = torch.Tensor(X_test_arr)\n",
        "test_targets = torch.Tensor(y_test_arr)\n",
        "\n",
        "train = TensorDataset(train_features, train_targets)\n",
        "val = TensorDataset(val_features, val_targets)\n",
        "test = TensorDataset(test_features, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "t-PuqtwVFTHv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"LSTMModel class extends nn.Module class and works as a constructor for LSTMs.\n",
        "\n",
        "       LSTMModel class initiates a LSTM module based on PyTorch's nn.Module class.\n",
        "       It has only two methods, namely init() and forward(). While the init()\n",
        "       method initiates the model with the given input parameters, the forward()\n",
        "       method defines how the forward propagation needs to be calculated.\n",
        "       Since PyTorch automatically defines back propagation, there is no need\n",
        "       to define back propagation method.\n",
        "\n",
        "       Attributes:\n",
        "           hidden_dim (int): The number of nodes in each layer\n",
        "           layer_dim (str): The number of layers in the network\n",
        "           lstm (nn.LSTM): The LSTM model constructed with the input parameters.\n",
        "           fc (nn.Linear): The fully connected layer to convert the final state\n",
        "                           of LSTMs to our desired output shape.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        \"\"\"The __init__ method that initiates a LSTM instance.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): The number of nodes in the input layer\n",
        "            hidden_dim (int): The number of nodes in each layer\n",
        "            layer_dim (int): The number of layers in the network\n",
        "            output_dim (int): The number of nodes in the output layer\n",
        "            dropout_prob (float): The probability of nodes being dropped out\n",
        "\n",
        "        \"\"\"\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"The forward method takes input tensor x and does forward propagation\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor of the shape (batch size, sequence length, input_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor of the shape (batch size, output_dim)\n",
        "\n",
        "        \"\"\"\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "\n",
        "        # Initializing cell state for first input with zeros\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nzq3n7QmFTKn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model, model_params):\n",
        "    models = {\n",
        "        \"lstm\": LSTMModel    \n",
        "        }\n",
        "    return models.get(model.lower())(**model_params)"
      ],
      "metadata": {
        "id": "AW-gic85JO0g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimization:\n",
        "    \"\"\"Optimization is a helper class that allows training, validation, prediction.\n",
        "\n",
        "    Optimization is a helper class that takes model, loss function, optimizer function\n",
        "    learning scheduler (optional), early stopping (optional) as inputs. In return, it\n",
        "    provides a framework to train and validate the models, and to predict future values\n",
        "    based on the models.\n",
        "\n",
        "    Attributes:\n",
        "        model (RNNModel, LSTMModel, GRUModel): Model class created for the type of RNN\n",
        "        loss_fn (torch.nn.modules.Loss): Loss function to calculate the losses\n",
        "        optimizer (torch.optim.Optimizer): Optimizer function to optimize the loss function\n",
        "        train_losses (list[float]): The loss values from the training\n",
        "        val_losses (list[float]): The loss values from the validation\n",
        "        last_epoch (int): The number of epochs that the models is trained\n",
        "    \"\"\"\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model (RNNModel, LSTMModel, GRUModel): Model class created for the type of RNN\n",
        "            loss_fn (torch.nn.modules.Loss): Loss function to calculate the losses\n",
        "            optimizer (torch.optim.Optimizer): Optimizer function to optimize the loss function\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "    def train_step(self, x, y):\n",
        "        \"\"\"The method train_step completes one step of training.\n",
        "\n",
        "        Given the features (x) and the target values (y) tensors, the method completes\n",
        "        one step of the training. First, it activates the train mode to enable back prop.\n",
        "        After generating predicted values (yhat) by doing forward propagation, it calculates\n",
        "        the losses by using the loss function. Then, it computes the gradients by doing\n",
        "        back propagation and updates the weights by calling step() function.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Tensor for features to train one step\n",
        "            y (torch.Tensor): Tensor for target values to calculate losses\n",
        "\n",
        "        \"\"\"\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        yhat = self.model(x)\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
        "        \"\"\"The method train performs the model training\n",
        "\n",
        "        The method takes DataLoaders for training and validation datasets, batch size for\n",
        "        mini-batch training, number of epochs to train, and number of features as inputs.\n",
        "        Then, it carries out the training by iteratively calling the method train_step for\n",
        "        n_epochs times. If early stopping is enabled, then it  checks the stopping condition\n",
        "        to decide whether the training needs to halt before n_epochs steps. Finally, it saves\n",
        "        the model in a designated file path.\n",
        "\n",
        "        Args:\n",
        "            train_loader (torch.utils.data.DataLoader): DataLoader that stores training data\n",
        "            val_loader (torch.utils.data.DataLoader): DataLoader that stores validation data\n",
        "            batch_size (int): Batch size for mini-batch training\n",
        "            n_epochs (int): Number of epochs, i.e., train steps, to train\n",
        "            n_features (int): Number of feature columns\n",
        "\n",
        "        \"\"\"\n",
        "        model_path = f'{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            batch_losses = []\n",
        "            for x_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.view([batch_size, -1, n_features]).to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "                loss = self.train_step(x_batch, y_batch)\n",
        "                batch_losses.append(loss)\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, n_features]).to(self.device)\n",
        "                    y_val = y_val.to(self.device)\n",
        "                    self.model.eval()\n",
        "                    yhat = self.model(x_val)\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch <= 10) | (epoch % 50 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "        torch.save(self.model.state_dict(), 'model_test_LSTM')\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
        "        \"\"\"The method evaluate performs the model evaluation\n",
        "\n",
        "        The method takes DataLoaders for the test dataset, batch size for mini-batch testing,\n",
        "        and number of features as inputs. Similar to the model validation, it iteratively\n",
        "        predicts the target values and calculates losses. Then, it returns two lists that\n",
        "        hold the predictions and the actual values.\n",
        "\n",
        "        Note:\n",
        "            This method assumes that the prediction from the previous step is available at\n",
        "            the time of the prediction, and only does one-step prediction into the future.\n",
        "\n",
        "        Args:\n",
        "            test_loader (torch.utils.data.DataLoader): DataLoader that stores test data\n",
        "            batch_size (int): Batch size for mini-batch training\n",
        "            n_features (int): Number of feature columns\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The values predicted by the model\n",
        "            list[float]: The actual values in the test set.\n",
        "\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            predictions = []\n",
        "            values = []\n",
        "            for x_test, y_test in test_loader:\n",
        "                x_test = x_test.view([batch_size, -1, n_features]).to(self.device)\n",
        "                y_test = y_test.to(self.device)\n",
        "                self.model.eval()\n",
        "                yhat = self.model(x_test)\n",
        "                predictions.append(yhat.cpu().detach().numpy())\n",
        "                values.append(y_test.cpu().detach().numpy())\n",
        "\n",
        "        return predictions, values\n",
        "\n",
        "    def plot_losses(self):\n",
        "        \"\"\"The method plots the calculated loss values for training and validation\n",
        "        \"\"\"\n",
        "        plt.plot(self.train_losses, label=\"Training loss\")\n",
        "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Losses\")\n",
        "        plt.show()\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "LEAGMgmZJO3G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(X_train.columns)\n",
        "output_dim = 1\n",
        "hidden_dim = 64\n",
        "layer_dim = 3\n",
        "batch_size = 64\n",
        "dropout = 0.2\n",
        "n_epochs = 2\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6"
      ],
      "metadata": {
        "id": "dhNmiu2mJO5g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout}\n",
        "\n",
        "model = get_model('lstm', model_params)\n",
        "model.to(device)\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "URtDrlZmNGPG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer, device = device)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
        "opt.plot_losses()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "8Pj1KNiHJO8F",
        "outputId": "e09cc774-2cf2-465f-dd7d-3f89e117c2b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/2] Training loss: 0.0155\t Validation loss: 0.0139\n",
            "[2/2] Training loss: 0.0115\t Validation loss: 0.0108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, values = opt.evaluate(\n",
        "    test_loader_one,\n",
        "    batch_size=1,\n",
        "    n_features=input_dim\n",
        ")"
      ],
      "metadata": {
        "id": "SPKeLBmJJO-Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_transform(scaler, df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = scaler.inverse_transform(df[col])\n",
        "    return df\n",
        "\n",
        "\n",
        "def format_predictions(predictions, values, df_test, scaler):\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
        "    df_result = df_result.sort_index()\n",
        "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
        "    return df_result\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    result_metrics = {'mae' : mean_absolute_error(df.value, df.prediction),\n",
        "                      'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,\n",
        "                      'r2' : r2_score(df.value, df.prediction)}\n",
        "    \n",
        "    print(\"Mean Absolute Error:       \", result_metrics[\"mae\"])\n",
        "    print(\"Root Mean Squared Error:   \", result_metrics[\"rmse\"])\n",
        "    print(\"R^2 Score:                 \", result_metrics[\"r2\"])\n",
        "    return result_metrics"
      ],
      "metadata": {
        "id": "uBiFl79oJPA7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = format_predictions(predictions, values, X_test, scaler)"
      ],
      "metadata": {
        "id": "Io_yirvJFTNS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_metrics = calculate_metrics(df_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0x__oFxFTQD",
        "outputId": "29ac08a7-c1a1-4976-d35f-32a72e4f2e0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error:        3892.2332\n",
            "Root Mean Squared Error:    4830.683595517306\n",
            "R^2 Score:                  0.4457855854656355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_baseline_model(df, test_ratio, target_col):\n",
        "    X, y = feature_label_split(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "\n",
        "    result = pd.DataFrame(y_test)\n",
        "    result[\"prediction\"] = prediction\n",
        "    result = result.sort_index()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "eZzibo00FTTC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_baseline = build_baseline_model(df_features, 0.2, 'value')\n",
        "baseline_metrics = calculate_metrics(df_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoWPCKJOumji",
        "outputId": "968a6aed-453e-4b2c-bf69-629b44077b72"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error:        3652.5844053105866\n",
            "Root Mean Squared Error:    4589.279608903664\n",
            "R^2 Score:                  0.4997931432605698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(df_result, df_baseline):\n",
        "    data = []\n",
        "    \n",
        "    value = go.Scatter(\n",
        "        x=df_result.index,\n",
        "        y=df_result.value,\n",
        "        mode=\"lines\",\n",
        "        name=\"values\",\n",
        "        marker=dict(),\n",
        "        text=df_result.index,\n",
        "        line=dict(color=\"rgba(0,0,0, 0.3)\"),\n",
        "    )\n",
        "    data.append(value)\n",
        "\n",
        "    baseline = go.Scatter(\n",
        "        x=df_baseline.index,\n",
        "        y=df_baseline.prediction,\n",
        "        mode=\"lines\",\n",
        "        line={\"dash\": \"dot\"},\n",
        "        name='linear regression',\n",
        "        marker=dict(),\n",
        "        text=df_baseline.index,\n",
        "        opacity=0.8,\n",
        "    )\n",
        "    data.append(baseline)\n",
        "    \n",
        "    prediction = go.Scatter(\n",
        "        x=df_result.index,\n",
        "        y=df_result.prediction,\n",
        "        mode=\"lines\",\n",
        "        line={\"dash\": \"dot\"},\n",
        "        name='predictions',\n",
        "        marker=dict(),\n",
        "        text=df_result.index,\n",
        "        opacity=0.8,\n",
        "    )\n",
        "    data.append(prediction)\n",
        "    \n",
        "    layout = dict(\n",
        "        title=\"Predictions vs Actual Values for the dataset\",\n",
        "        xaxis=dict(title=\"Time\", ticklen=5, zeroline=False),\n",
        "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
        "    )\n",
        "\n",
        "    fig = dict(data=data, layout=layout)\n",
        "    iplot(fig)"
      ],
      "metadata": {
        "id": "5T3G2YPSummH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyo.init_notebook_mode()\n",
        "plot_predictions(df_result, df_baseline)"
      ],
      "metadata": {
        "id": "1AFZ5xpLyIsS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dGsj8bpGyIux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FLb6Q_YSyIxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CcnCFE-6umpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-Uz1_NIQumrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}